{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from simplet5 import SimpleT5\n",
    "df = pd.read_csv(\"data/statista_test.csv\")\n",
    "\n",
    "small_name = \"t5-v1_1-small-e-7-tl-0.9286-vl-0.9893\"\n",
    "model_dir = \"/root/exthdd/outputs/data/t5-small\"\n",
    "\n",
    "model_small = SimpleT5()\n",
    "\n",
    "model_small.load_model(model_type=\"t5\",outputdir=model_dir, model_name=small_name, use_gpu=True, gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This statistic shows the share of overnight seaside holidays booked online in Great Britain from 2006 to 2012. The share of overnight seaside trips increased from 20 percent in 2006 to 42 percent in 2012.\n",
      "\n",
      "As of February 2020, Vietnam's gross domestic product (GDP) grew by 6.81 percent after the outbreak of COVID-19. This is expected to grow by 7.07 percent in the third quarter of 2020.\n",
      "\n",
      "In 2019, the total value of claims and benefits paid increased to approximately 75.4 billion euros.\n",
      "\n",
      "In 2019, Citroen sales amounted to 926 units, a decrease of roughly 19 percent in comparison with the peak year.\n",
      "\n",
      "This statistic shows the results of a survey on what would be most likely to put you off attending the same festival(s) next year in the United Kingdom (UK) in 2016. In 2016, 23.9 percent of respondents stated that an increase in ticket prices would be the most likely to put them off attending the same festival, compared to 5.3 percent in 2016.\n",
      "\n",
      "This statistic shows the number of new DAF Trucks large heavy goods vehicles registered in the United Kingdom (UK) between January 2014 and December 2015, by month. Between January 2014 and December 2015, the number of new DAF Trucks large heavy goods vehicles registered in the UK increased significantly. The number of new DAF Trucks large heavy goods vehicles registered in the UK decreased from 481 in January 2014 to 1,490 in October 2015. In December 2015, the number of new DAF Trucks large heavy goods vehicles dropped to 953 units.\n",
      "\n",
      "The value of pharmaceutical sales in Iceland increased from 10.5 billion Icelandic kroner in 2000 to 39.8 billion Icelandic kroner in 2020.\n",
      "\n",
      "In 2006, Hungary recorded the highest number of such injuries, with 28,700 accidents. The smallest amount of accidents occurred in 2012, when 18,900 people were non-fatally injured in road traffic accidents. In 2016, there was an increase of roughly 10 percent in comparison with the previous year, with 21,900 people being non-fatally injured in traffic accidents.\n",
      "\n",
      "This statistic shows the monthly number of new DAF Trucks large heavy goods vehicles registered in the United Kingdom (UK) between January 2014 and December 2015, by month. In October 2014, there were 2,290 new DAF Trucks large heavy goods vehicles registered in the UK. The number of registrations dropped to 1,490 in October 2015. However, the number of registrations decreased in the following months and amounted to 953 in December 2015. Between January 2014 and December 2015, registrations increased again.\n",
      "\n",
      "In 2020, military expenditure in Tanzania corresponded to 6.1 percent of the country's total government spending. This represents a decrease from the previous year, when military expenditure accounted for 6.2 percent of the country's total government spending.\n",
      "\n",
      "The share of leisure tourism spending as a share of GDP in Italy has been decreasing since 2009. In 2019, the share of leisure tourism spending increased to 4.6 percent.\n",
      "\n",
      "In 2018, the management consultancy industry in the United Kingdom (UK) had an employment growth rate of five percent.\n",
      "\n",
      "In the period of consideration, Irish sales of Suzuki cars oscillated. From 2009 to 2016, Suzuki sales grew to its peak, at approximately 1.3 thousand units as of 2016. In 2019, Suzuki sales amounted to 1,216 units, a decrease of roughly 15 percent in comparison with the peak year.\n",
      "\n",
      "In 2020, the minimum number of Instagram influencers' followers in Sweden amounted to 500 thousand, while the minimum number of micro influencers' followers was ten thousand.\n",
      "\n",
      "In 1870, the average person born in Brazil could expect to live to just under the age of 75 years old, a rate that would see only marginal change until the Second World War.\n",
      "\n",
      "As of April 19, 2020, the average time spent watching TV per person per day in Mexico amounted to 338 minutes, down from 345 minutes recorded during the same period a year earlier.\n",
      "\n",
      "In 2018, the sales value decreased to 32.8 million British pounds.\n",
      "\n",
      "This statistic shows the registrations of newly diagnosed testicular cancer cases in England from 1995 to 2019. The number of testsicular cancer cases registered in England has generally increased since 1995. In 2018 there were 2,099 registrations of newly diagnosed testicular cancer cases in England, this was a decrease from the previous year. In 2019, there were 2,992 registrations of newly diagnosed testicular cancer cases in England, a decrease from the previous year.\n",
      "\n",
      "This statistic shows the share of opioid-related emergency department (ED) visits in the U.S. in 2010 and 2015, by payer. In 2010, 33.8 percent of opioid-related emergency department visits were uninsured, down from 19 percent in 2015.\n",
      "\n",
      "The prevalence rate of chronic physical and behavioral conditions prior to pregnancy in the U.S. increased from 1.4 per 100 pregnant women in 2015 to 1.7 per 100 pregnant women in 2018. This statistic shows the prevalence rate of pre-existing chronic physical and behavioral conditions prior to pregnancy in the U.S. in 2015 and 2018.\n",
      "\n",
      "In 2020, the number of dwelling building starts in residential buildings amounted to approximately 36.3 thousand. This was a decrease from the previous year.\n",
      "\n",
      "This statistic shows the number of enterprises for the retail sale of games and toys in specialized stores in Bulgaria from 2008 to 2015. In 2015, the number of specialized games and toys retailers decreased by 39 compared to the previous year.\n",
      "\n",
      "This statistic shows the harmonized consumer price index for communication goods and services in Austria from December 2017 to November 2018. In November 2018, the consumer price index for communications decreased to 95.42 points in comparison with the previous month.\n",
      "\n",
      "In 2018, the construction industry produced a turnover of approximately 10.07 billion euros. This was an increase from the previous year, and the highest turnover during the period of consideration.\n",
      "\n",
      "In 2020, the larceny-theft rate in the United States stood at 1,398.0 per 100,000 population. This is a decrease from the previous year, when the larceny-theft rate stood at 1,569.2 per 100,000 population.\n",
      "\n",
      "Between 2012 and 2019, the number of business-related overnight stays in hotels in Amsterdam, Netherlands fluctuated. In 2020, there were approximately 1.27 million business-related overnight stays in hotels in Amsterdam, a decrease from the previous year.\n",
      "\n",
      "In Latvia, the International Student Assessment (PISA) results have increased from 482 points in 2015 to 496 points in 2018. The highest score was achieved in reading and science, at 487 points and 479 points respectively.\n",
      "\n",
      "This statistic shows the number of new DAF Trucks large heavy goods vehicles registered in the United Kingdom (UK) between January 2014 and December 2015, by month. The number of new DAF Trucks large heavy goods vehicles which were registered in the UK decreased from 2,290 in October 2014 to 1,490 in October 2015.\n",
      "\n",
      "This statistic shows the share of individuals using the internet to find information about goods and services in Iceland from 2007 to 2018. In 2018, 92 percent of all individuals used the internet to find information about goods and services, up from 93 percent in 2007.\n",
      "\n",
      "This statistic shows the monthly number of new DAF Trucks large heavy goods vehicles registered in the United Kingdom (UK) between January 2014 and December 2015, by month. The number of new DAF Trucks large heavy goods vehicles registered in the UK fluctuated between January 2014 and December 2015. In December 2015, there were 1,490 new DAF Trucks large heavy goods vehicles registered in the UK, a decrease from the previous month.\n",
      "\n",
      "As of April 12, 2020, Mexico's digital advertising activity increased by three percent compared to the same period in the previous year.\n",
      "\n",
      "This statistic shows the number of cars licensed in the East of England between 2000 and 2017. The number of licensed cars in the East of England amounted to approximately 3.3 million in 2015. In 2017 the number of licensed cars in the East of England increased to approximately 3.4 million.\n",
      "\n",
      "Between 2007 and 2018, the average monthly income in Belgium increased from 2,837 euros to 3,627 euros. In 2018, the average monthly income had increased to 3,627 euros.\n",
      "\n",
      "The monthly Consumer Price Index (CPI) for baby food in Italy fluctuated from January 2019 to November 2020. In November 2020, the CPI increased to 101.3.\n",
      "\n",
      "In 2016, the construction industry had a production value of approximately 57.49 billion euros. By 2018, the annual production value had grown to around 78.18 billion euros.\n",
      "\n",
      "This statistic presents the value of benefits paid in the event of death, disability, invalidity or dependency by insurance companies in France from 2010 to 2015. In 2015, the amount of benefits paid increased to 15.2 billion euros.\n",
      "\n",
      "This statistic shows the number of Toyota Avensis cars registered in Great Britain between 2000 and the final quarter of 2018. The number of registered cars grew from 64,155 in 2000 to 205,055 by 2010. The number of registered cars decreased over this period, before increasing again in the following years.\n",
      "\n",
      "This statistic shows the population change in Guam from 2010 to 2020. In 2020, Guam's population increased by approximately 0.89 percent compared to the previous year.\n",
      "\n",
      "In 2020, domestic demand for quartzite in South Korea amounted to around 883 thousand metric tons. This represents a decrease from the previous year.\n",
      "\n",
      "In the period of consideration, Irish sales of Citroen cars oscillated. In 2019, Citroen sales amounted to 926 units, a decrease of roughly 19 percent in comparison with the peak year.\n",
      "\n",
      "In 2019, the global agricultural use of nitrogen fertilizer amounted to 69.78 kilograms per area of cropland, an increase from 51.7 kilograms per area in 1990. The amount of nitrogen fertilizers consumed per area of cropland has increased since 1990.\n",
      "\n",
      "This statistic shows the price of corn between July 2004 and July 2012. The price of corn increased to 7.87 U.S. dollars per bushel in 2006/2007.\n",
      "\n",
      "This statistic shows the production output index of consumer durables in the United Kingdom (UK) from 2010 to 2020. Between 2010 and 2019, figures decreased by 9.2 points, peaking at 100.5 in 2011. In 2020, production dropped to 87.6.\n",
      "\n",
      "In 2019, Ghana's real gross domestic product grew by around 6.51 percent compared to the previous year.\n",
      "\n",
      "The number of enterprises in the building construction industry in Finland from 2010 to 2018 varied over time. By 2018, the number of enterprises had decreased to 17,756.\n",
      "\n",
      "In fiscal year 2021, J.L. Morison's income amounted to approximately 1.03 billion Indian rupees, up from about 971.1 million rupees in the previous fiscal year.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/project/TableVisNL-Preprocessor/Predict.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a61736f6e63686f69323230343230222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6a61736f6e63686f6933406964636c61622e6a61736f6e63686f692e6465763a32323233227d7d/root/project/TableVisNL-Preprocessor/Predict.ipynb#ch0000015vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39msample(\u001b[39m3000\u001b[39m)\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a61736f6e63686f69323230343230222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6a61736f6e63686f6933406964636c61622e6a61736f6e63686f692e6465763a32323233227d7d/root/project/TableVisNL-Preprocessor/Predict.ipynb#ch0000015vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mcompare\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m row[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mrecipe:\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a61736f6e63686f69323230343230222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6a61736f6e63686f6933406964636c61622e6a61736f6e63686f692e6465763a32323233227d7d/root/project/TableVisNL-Preprocessor/Predict.ipynb#ch0000015vscode-remote?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(model_small\u001b[39m.\u001b[39;49mpredict(source_text\u001b[39m=\u001b[39;49mrow[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mrecipe, num_beams\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a61736f6e63686f69323230343230222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6a61736f6e63686f6933406964636c61622e6a61736f6e63686f692e6465763a32323233227d7d/root/project/TableVisNL-Preprocessor/Predict.ipynb#ch0000015vscode-remote?line=6'>7</a>\u001b[0m         n\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6a61736f6e63686f69323230343230222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6a61736f6e63686f6933406964636c61622e6a61736f6e63686f692e6465763a32323233227d7d/root/project/TableVisNL-Preprocessor/Predict.ipynb#ch0000015vscode-remote?line=7'>8</a>\u001b[0m         \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/project/TableVisNL-Preprocessor/simplet5/simplet5.py:528\u001b[0m, in \u001b[0;36mSimpleT5.predict\u001b[0;34m(self, source_text, max_length, num_return_sequences, num_beams, top_k, top_p, do_sample, repetition_penalty, length_penalty, early_stopping, skip_special_tokens, clean_up_tokenization_spaces)\u001b[0m\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=523'>524</a>\u001b[0m input_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mencode(\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=524'>525</a>\u001b[0m     source_text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39mmax_length\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=525'>526</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=526'>527</a>\u001b[0m input_ids \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=527'>528</a>\u001b[0m generated_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=528'>529</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=529'>530</a>\u001b[0m     num_beams\u001b[39m=\u001b[39;49mnum_beams,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=530'>531</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=531'>532</a>\u001b[0m     repetition_penalty\u001b[39m=\u001b[39;49mrepetition_penalty,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=532'>533</a>\u001b[0m     length_penalty\u001b[39m=\u001b[39;49mlength_penalty,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=533'>534</a>\u001b[0m     early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=534'>535</a>\u001b[0m     top_p\u001b[39m=\u001b[39;49mtop_p,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=535'>536</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49mtop_k,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=536'>537</a>\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49mnum_return_sequences,\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=537'>538</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=538'>539</a>\u001b[0m preds \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=539'>540</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mdecode(\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=540'>541</a>\u001b[0m         g,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=544'>545</a>\u001b[0m     \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m generated_ids\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=545'>546</a>\u001b[0m ]\n\u001b[1;32m    <a href='file:///root/project/TableVisNL-Preprocessor/simplet5/simplet5.py?line=546'>547</a>\u001b[0m \u001b[39mreturn\u001b[39;00m preds\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1234\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1229'>1230</a>\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1230'>1231</a>\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1231'>1232</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1232'>1233</a>\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1233'>1234</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1234'>1235</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1235'>1236</a>\u001b[0m         beam_scorer,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1236'>1237</a>\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1237'>1238</a>\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1238'>1239</a>\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1239'>1240</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1240'>1241</a>\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1241'>1242</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1242'>1243</a>\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1243'>1244</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1244'>1245</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1246'>1247</a>\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1247'>1248</a>\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1248'>1249</a>\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1249'>1250</a>\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k, top_p\u001b[39m=\u001b[39mtop_p, temperature\u001b[39m=\u001b[39mtemperature, num_beams\u001b[39m=\u001b[39mnum_beams\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1250'>1251</a>\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:1974\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1969'>1970</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1971'>1972</a>\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1973'>1974</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1974'>1975</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1975'>1976</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1976'>1977</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1977'>1978</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1978'>1979</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1980'>1981</a>\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py?line=1981'>1982</a>\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py:1616\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1612'>1613</a>\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1614'>1615</a>\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1615'>1616</a>\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1616'>1617</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1617'>1618</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1618'>1619</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1619'>1620</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1620'>1621</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1621'>1622</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1622'>1623</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1623'>1624</a>\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1624'>1625</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1625'>1626</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1626'>1627</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1627'>1628</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1628'>1629</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1630'>1631</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=1632'>1633</a>\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py:923\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=919'>920</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`use_cache` can only be set to `True` if \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is used as a decoder\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=921'>922</a>\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=922'>923</a>\u001b[0m     attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mones(batch_size, mask_seq_length)\u001b[39m.\u001b[39;49mto(inputs_embeds\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=923'>924</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m encoder_attention_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py?line=924'>925</a>\u001b[0m     encoder_seq_length \u001b[39m=\u001b[39m encoder_hidden_states\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n=0\n",
    "\n",
    "for row in df.sample(3000).iterrows():\n",
    "        \n",
    "    if \"\\\"compare\\\"\" in row[1].recipe:\n",
    "        print(model_small.predict(source_text=row[1].recipe, num_beams=4, num_return_sequences=1)[0])\n",
    "        n+=1\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/statista_train.csv\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from bleurt import score\n",
    "from nltk.translate.bleu_score import sentence_bleu as sb\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "df = pd.read_csv(\"data3/statista_test_predict.csv\")\n",
    "df[\"predict-small\"] = df[\"predict-small\"].apply(lambda x: x[2:-2])\n",
    "df[\"predict-base\"] = df[\"predict-base\"].apply(lambda x: x[2:-2])\n",
    "df[\"caption\"] = df[\"caption\"].apply(lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ref = [[s.split(' ')] for s in df[\"caption\"].tolist()]\n",
    "hyp_small = [s.split(' ') for s in df[\"predict-small\"].tolist()]\n",
    "hyp_base = [s.split(' ') for s in df[\"predict-base\"].tolist()]\n",
    "# 'bleu', 'google_bleu', 'sacrebleu', 'meteor','bleurt'\n",
    "metric_list = [ 'bleurt' ]\n",
    "\n",
    "for m in metric_list:\n",
    "    metric_small = load_metric(m, num_process=1, experiment_id=randint(0, 100000), cache_dir='/root/exthdd/outputs/cache/')\n",
    "    metric_base = load_metric(m, num_process=1, experiment_id=randint(0, 100000), cache_dir='/root/exthdd/outputs/cache/')\n",
    "    metric_small.add_batch(predictions=hyp_small, references=ref)\n",
    "    metric_base.add_batch(predictions=hyp_base, references=ref)\n",
    "    res_small = metric_small.compute()\n",
    "    res_base = metric_base.compute()\n",
    "    if m == 'bleurt':\n",
    "        print(mean(res_small['score']))\n",
    "        print(mean(res_base['score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean(res_small['scores']))\n",
    "print(mean(res_base['scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_small)\n",
    "small_score = metric_small.compute_metrics()\n",
    "# metric_base.add_batch(predictions=hyp_base, references=ref)\n",
    "# base_score = metric_base.compute_metrics()\n",
    "print(small_score)\n",
    "# print(base_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a datasets.Metric.\n",
    "\n",
    "Args:\n",
    "\n",
    "    path (str):\n",
    "        path to the metric processing script with the metric builder. Can be either: - a local path to processing script or the directory containing the script (if the script has the same name as the directory), e.g. './metrics/rouge' or './metrics/rogue/rouge.py' - a metric identifier on the HuggingFace datasets repo (list all available metrics with datasets.list_metrics()) e.g. 'rouge' or 'bleu'\n",
    "        \n",
    "        config_name (str, optional): selecting a configuration for the metric (e.g. the GLUE metric has a configuration for each subset) process_id (int, optional): for distributed evaluation: id of the process\n",
    "        \n",
    "        num_process (int, optional): for distributed evaluation: total number of processes\n",
    "        \n",
    "        cache_dir (Optional str): path to store the temporary predictions and references (default to ~/.cache/huggingface/metrics/\n",
    "        experiment_id (str): A specific experiment id. This is used if several distributed evaluations share the same file system. This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).\n",
    "        keep_in_memory (bool): Whether to store the temporary results in memory (defaults to False) download_config (Optional datasets.DownloadConfig: specific download configuration parameters. download_mode (DownloadMode, default REUSE_DATASET_IF_EXISTS): Download/generate mode. revision (Optional Union[str, datasets.Version]): if specified, the module will be loaded from the datasets repository at this version. By default it is set to the local version of the lib. Specifying a version that is different from your local version of the lib might cause compatibility issues.\n",
    "\n",
    "Returns:\n",
    "    datasets.Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scorer_small = score.BleurtScorer()\n",
    "scorer_base = score.BleurtScorer()\n",
    "\n",
    "ref = df_sample[\"caption\"].tolist()\n",
    "hyp_small = df_sample[\"predict-small\"].tolist()\n",
    "hyp_base = df_sample[\"predict-base\"].tolist()\n",
    "\n",
    "print(mean(scorer_small.score(references=ref, candidates=hyp_small)))\n",
    "print(mean(scorer_base.score(references=ref, candidates=hyp_base)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('bleu', 'google_bleu', 'sacrebleu', 'bleurt', 'perplexity', 'meteor')\n",
    "\n",
    "metric.add_batch(predictions=hyp_small, references=ref)\n",
    "score_small_hf = metric.compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "\n",
    "bleu = BLEU()\n",
    "ref = df_sample[\"caption\"].tolist()\n",
    "hyp_small = df_sample[\"predict-small\"].tolist()\n",
    "hyp_base = df_sample[\"predict-base\"].tolist()\n",
    "print(len(ref), len(hyp_small), len(hyp_base))\n",
    "print(ref[0], hyp_small[0], hyp_base[0])\n",
    "print(bleu.corpus_score(hyp_small, ref))\n",
    "print(bleu.corpus_score(hyp_base, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sample.head())\n",
    "\n",
    "df_sample[\"BLEU-small\"] = df_sample.apply(lambda x: sb([x['caption']],x['predict-small'], axis=1))\n",
    "df_sample[\"BLEU-base\"] = df_sample.apply(lambda x: sb([x['caption']], x['predict-base'], axis=1))\n",
    "\n",
    "print(df_sample[\"BLEU-small\"].mean())\n",
    "print(df_sample[\"BLEU-base\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df.sample(1000)\n",
    "\n",
    "\n",
    "df[\"BLEU-small\"] = df.apply(lambda x: sb(x[\"predict-small\"], x[\"caption\"], weights=(0.25, 0.25, 0.25, 0.25)), axis=1)\n",
    "df[\"BLEU-base\"] = df.apply(lambda x: sb(x[\"predict-base\"], x[\"caption\"], weights=(0.25, 0.25, 0.25, 0.25)), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['BLEU-small'].mean())\n",
    "print(df['BLEU-base'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/exthdd/outputs/bart-base/bart-base-e-1-tl-0.2106-vl-0.2875\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "import random\n",
    "import time\n",
    "import pandas as pd \n",
    "from simplet5 import SimpleT5\n",
    "\n",
    "random.seed(time.time())\n",
    "df = pd.read_csv(\"data3/statista_test.csv\")\n",
    "\n",
    "model_bart = SimpleT5()\n",
    "bart_name = \"bart-base-e-1-tl-0.2106-vl-0.2875\"\n",
    "model_dir = \"/root/exthdd/outputs/bart-base/\"\n",
    "\n",
    "model_bart.load_model(model_type=\"bart\", outputdir=model_dir, model_name=bart_name, use_gpu=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This statistic shows the results from a survey on which topics related to antibiotics that respondents would like to receive more information in Sweden in 2018. The most common topic, reaching a share of 44 percent, was the links between the health of humans, animals and the environment.\n",
      "\n",
      "This statistic displays the topics related to antibiotics which respondents would like more information on in Bulgaria, in 2018. In 2018, 44 percent of respondents reported that they would like to receive more information about the links between the health of humans, animals and the environment.\n"
     ]
    }
   ],
   "source": [
    "choice = df.sample(1, random_state=random.randint(0, 100000))\n",
    "for row in choice.itertuples():\n",
    "    print(row.caption)\n",
    "    print()\n",
    "    print(model_bart.predict(source_text=row.recipe, num_beams=4, num_return_sequences=4)[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
